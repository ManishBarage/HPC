{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-mzvM5hsHmc",
        "outputId": "f906151a-59ca-4ad9-b4f5-f1f2523c13de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ],
      "source": [
        "pip install nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-Ng3OioruYA",
        "outputId": "db9a2e4f-bb39-4634-d119-c61664896dfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting q1.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile q1.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cstdlib>\n",
        "#include <ctime>\n",
        "#include <chrono>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void vectorAddCUDA(const float* A, const float* B, float* C, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < N) {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "void vectorAddCPU(const float* A, const float* B, float* C, int N) {\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 10000000;\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    float *h_A = (float*)malloc(size);\n",
        "    float *h_B = (float*)malloc(size);\n",
        "    float *h_C_cpu = (float*)malloc(size); // Result for CPU\n",
        "    float *h_C_gpu = (float*)malloc(size); // Result for GPU\n",
        "\n",
        "    srand(time(0));\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_A[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "        h_B[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // CPU (Serial) Execution\n",
        "    auto start_cpu = chrono::high_resolution_clock::now();\n",
        "    vectorAddCPU(h_A, h_B, h_C_cpu, N);\n",
        "    auto end_cpu = chrono::high_resolution_clock::now();\n",
        "    chrono::duration<float, milli> cpu_duration = end_cpu - start_cpu;\n",
        "    cout << \"CPU Execution Time: \" << cpu_duration.count() << \" ms\" << endl;\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define block and grid sizes\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (N + blockSize - 1) / blockSize;\n",
        "\n",
        "    // GPU (CUDA) Execution\n",
        "    auto start_gpu = chrono::high_resolution_clock::now();\n",
        "    vectorAddCUDA<<<gridSize, blockSize>>>(d_A, d_B, d_C, N);\n",
        "    cudaDeviceSynchronize();\n",
        "    auto end_gpu = chrono::high_resolution_clock::now();\n",
        "    chrono::duration<float, milli> gpu_duration = end_gpu - start_gpu;\n",
        "    cout << \"GPU Execution Time: \" << gpu_duration.count() << \" ms\" << endl;\n",
        "\n",
        "    cudaMemcpy(h_C_gpu, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    float speedup = cpu_duration.count() / gpu_duration.count();\n",
        "    cout << \"Speedup (CPU Time / GPU Time): \" << speedup << endl;\n",
        "\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C_cpu);\n",
        "    free(h_C_gpu);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0jZSQsxsFxE",
        "outputId": "de57eab2-a022-479b-f270-e7e3009740c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU Execution Time: 58.4208 ms\n",
            "GPU Execution Time: 0.002466 ms\n",
            "Speedup (CPU Time / GPU Time): 23690.5\n"
          ]
        }
      ],
      "source": [
        "! nvcc -o q1 q1.cu\n",
        "!./q1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZIohwiSGmFF",
        "outputId": "2b6b02b1-9a8c-4f1b-9221-ce1dd9a3e750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting q2.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile q2.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cstdlib>\n",
        "#include <ctime>\n",
        "#include <chrono>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "\n",
        "\n",
        "// CUDA kernel for matrix addition\n",
        "__global__ void matrixAddCUDA(const float* A, const float* B, float* C, int M, int N) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < M && col < N) {\n",
        "        int index = row * N + col;\n",
        "        C[index] = A[index] + B[index];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Serial CPU implementation for matrix addition\n",
        "void matrixAddCPU(const float* A, const float* B, float* C, int M, int N) {\n",
        "    for (int i = 0; i < M; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            int index = i * N + j;\n",
        "            C[index] = A[index] + B[index];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int M = 1000; // Number of rows\n",
        "    int N = 1000; // Number of columns\n",
        "    size_t size = M * N * sizeof(float);\n",
        "\n",
        "    // Allocate host memory\n",
        "    float *h_A = (float*)malloc(size);\n",
        "    float *h_B = (float*)malloc(size);\n",
        "    float *h_C_cpu = (float*)malloc(size); // Result for CPU\n",
        "    float *h_C_gpu = (float*)malloc(size); // Result for GPU\n",
        "\n",
        "    // Initialize matrices A and B with random values\n",
        "    srand(time(0));\n",
        "    for (int i = 0; i < M * N; i++) {\n",
        "        h_A[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "        h_B[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // CPU (Serial) Execution\n",
        "    auto start_cpu = chrono::high_resolution_clock::now();\n",
        "    matrixAddCPU(h_A, h_B, h_C_cpu, M, N);\n",
        "    auto end_cpu = chrono::high_resolution_clock::now();\n",
        "    chrono::duration<float, milli> cpu_duration = end_cpu - start_cpu;\n",
        "    cout << \"CPU Execution Time: \" << cpu_duration.count() << \" ms\" << endl;\n",
        "\n",
        "    // Allocate device memory\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "    CUDA_CHECK_ERROR();\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define block and grid sizes\n",
        "    dim3 blockSize(16, 16); // 16x16 threads per block\n",
        "    dim3 gridSize((N + blockSize.x - 1) / blockSize.x, (M + blockSize.y - 1) / blockSize.y);\n",
        "\n",
        "    // GPU (CUDA) Execution\n",
        "    auto start_gpu = chrono::high_resolution_clock::now();\n",
        "    matrixAddCUDA<<<gridSize, blockSize>>>(d_A, d_B, d_C, M, N);\n",
        "    cudaDeviceSynchronize(); // Ensure kernel has finished executing\n",
        "    auto end_gpu = chrono::high_resolution_clock::now();\n",
        "\n",
        "    chrono::duration<float, milli> gpu_duration = end_gpu - start_gpu;\n",
        "    cout << \"GPU Execution Time: \" << gpu_duration.count() << \" ms\" << endl;\n",
        "\n",
        "    // Copy result from device to host\n",
        "    cudaMemcpy(h_C_gpu, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Calculate speedup\n",
        "    float speedup = cpu_duration.count() / gpu_duration.count();\n",
        "    cout << \"Speedup (CPU Time / GPU Time): \" << speedup << endl;\n",
        "\n",
        "    // Free device and host memory\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C_cpu);\n",
        "    free(h_C_gpu);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CyK6KmnGxvb",
        "outputId": "4fa225ae-bec5-41fd-d53d-977925fa0b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Execution Time: 11.8038 ms\n",
            "GPU Execution Time: 0.003225 ms\n",
            "Speedup (CPU Time / GPU Time): 3660.1\n"
          ]
        }
      ],
      "source": [
        "!nvcc -o q2 q2.cu\n",
        "!./q2"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}